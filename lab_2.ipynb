{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GryyPwukmm_a"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00yPuBq0m7Cs",
        "outputId": "2354e48d-01c2-4269-f81f-366de9c29ef9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVn4ynnxmm_b",
        "outputId": "181cd539-fa66-415e-e1cf-551f515b439e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4GnvjdIkmm_c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import reuters\n",
        "# разделение данных на тренировочный, валидационный и тестовый наборы\n",
        "from sklearn.model_selection import train_test_split\n",
        "# очистка данных\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "# преобразование текста в числовое представление\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# обработка меток\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "# bert\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "# оптимизаторы и планировщики\n",
        "from torch.optim import AdamW, SGD, RMSprop\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnzezqtjmm_d",
        "outputId": "ef3de8a9-195a-4256-ca28-67a592d9e342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# загрузка данных\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# получение данных\n",
        "doc_ids = reuters.fileids()\n",
        "train_ids = [doc_id for doc_id in doc_ids if doc_id.startswith('training')]\n",
        "test_ids = [doc_id for doc_id in doc_ids if doc_id.startswith('test')]\n",
        "\n",
        "train_data = [reuters.raw(doc_id) for doc_id in train_ids]\n",
        "train_labels = [reuters.categories(doc_id) for doc_id in train_ids]\n",
        "\n",
        "test_data = [reuters.raw(doc_id) for doc_id in test_ids]\n",
        "test_labels = [reuters.categories(doc_id) for doc_id in test_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sODPKm_dmm_d",
        "outputId": "39d8385f-cba5-4957-8897-cd159d808188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "тренировочные данные: 80\n",
            "валидационные данные: 20\n",
            "тестовые данные: 15\n"
          ]
        }
      ],
      "source": [
        "# разделение тренировочных данных на тренировочный и валидационный наборы\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(\n",
        "    train_data, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# вывод размеров наборов данных\n",
        "print(\"тренировочные данные:\", len(train_data))\n",
        "print(\"валидационные данные:\", len(val_data))\n",
        "print(\"тестовые данные:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6Myd8hHmm_e",
        "outputId": "f3499030-223c-4410-9785-602df2daa63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "очищенный тренировочный текст: universal holding corp ltuhco 4th qtr loss shr profit nil v profit nine ct net profit 2000 v profit 195000 rev 2623000 v 2577000 year shr loss 21 ct v profit 13 ct net loss 425000 v profit 278000 rev 154 mln v 8637000 note net includes capital gain 63000 v 211000 qtr 304000 v 292000 year current year net includes charge 716000 contract obligation former chairman\n"
          ]
        }
      ],
      "source": [
        "# инициализация стоп-слов и лемматизатора\n",
        "stop_words = set(stopwords.words('english'))  # для английского языка\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# функция для очистки текста\n",
        "def clean_text(text):\n",
        "    # удаление пунктуации\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # приведение к нижнему регистру\n",
        "    text = text.lower()\n",
        "\n",
        "    # токенизация\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # удаление стоп-слов\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # лемматизация\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# применение очистки ко всем данным\n",
        "train_data_cleaned = [clean_text(text) for text in train_data]\n",
        "val_data_cleaned = [clean_text(text) for text in val_data]\n",
        "test_data_cleaned = [clean_text(text) for text in test_data]\n",
        "# пример очищенных данных\n",
        "print(\"очищенный тренировочный текст:\", train_data_cleaned[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB0BWxZ7mm_e",
        "outputId": "dcee5e85-ba76-4475-c6c8-2a5ffdd17261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "тренировочные данные в числовом виде: [0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# создание векторизатора\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# обучение векторизатора на тренировочных данных\n",
        "X_train = vectorizer.fit_transform(train_data_cleaned)\n",
        "\n",
        "# преобразование валидационных и тестовых данных\n",
        "X_val = vectorizer.transform(val_data_cleaned)\n",
        "X_test = vectorizer.transform(test_data_cleaned)\n",
        "\n",
        "# пример числового представления\n",
        "print(\"тренировочные данные в числовом виде:\", X_train.toarray()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe8hANykmm_f",
        "outputId": "fa381f4b-ce56-4609-da1d-232eca69908a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "тренировочные метки: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['carcass', 'livestock', 'veg-oil'] will be ignored\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['carcass', 'copper', 'gold', 'ipi', 'livestock', 'lumber', 'oilseed', 'palm-oil', 'rice', 'rubber', 'soybean', 'tin', 'veg-oil'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# инициализация и преобразование меток\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(train_labels)\n",
        "y_val = mlb.transform(val_labels)\n",
        "y_test = mlb.transform(test_labels)\n",
        "\n",
        "# пример преобразованных меток\n",
        "print(\"тренировочные метки:\", y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viC-pnvlmm_f"
      },
      "source": [
        "Self-Attention — это механизм, который позволяет модели \"взвешивать\" важность каждого элемента последовательности относительно других элементов. Это помогает модели учитывать контекст и зависимости между словами в предложении.\n",
        "\n",
        "Multi-Head Attention — это расширение Self-Attention, где внимание вычисляется несколько раз параллельно с разными линейными проекциями Query, Key и Value. Это позволяет модели учитывать различные типы зависимостей в данных.\n",
        "\n",
        "Преимущества трансформера по сравнению с RNN и LSTM\n",
        "* Трансформеры обрабатывают всю последовательность одновременно, в отличие от RNN и LSTM, которые обрабатывают последовательность пошагово, что значительно ускоряет обучение.\n",
        "* Self-Attention позволяет модели учитывать зависимости между словами на любом расстоянии, в то время как RNN и LSTM страдают от проблемы затухания градиента при работе с длинными последовательностями.\n",
        "* Трансформеры легко масштабируются на большие объемы данных и параметров, что делает их идеальными для современных задач NLP.\n",
        "* Веса внимания в Self-Attention могут быть визуализированы, что позволяет лучше понять, как модель принимает решения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8RWeufhEmm_g"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def encode_texts(texts, labels, max_length=128):\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings, labels\n",
        "\n",
        "train_encodings, y_train = encode_texts(train_data_cleaned, train_labels)\n",
        "val_encodings, y_val = encode_texts(val_data_cleaned, val_labels)\n",
        "test_encodings, y_test = encode_texts(test_data_cleaned, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPfAkqdtmm_g"
      },
      "source": [
        "Для fine-tuning модели BERT можно использовать библиотеку transformers от Hugging Face. Вот пример кода для инициализации модели BERT:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8ynEzMmm_g",
        "outputId": "02206a80-93ca-44b2-ccf7-0cd65c32ff9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# инициализация модели для многоклассовой классификации\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(mlb.classes_),  # Количество классов\n",
        "    problem_type=\"multi_label_classification\"  # Указываем тип задачи\n",
        ")\n",
        "\n",
        "# передача модели на GPU (если доступно)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZoimG2mm_h"
      },
      "source": [
        "Настройка гиперпараметров:\n",
        "\n",
        "* **Количество слоев**. В BERT количество слоев (трансформерных блоков) фиксировано (например, 12 для bert-base-uncased). Вы можете использовать меньшие или большие версии BERT (например, bert-large-uncased).\n",
        "* Размерность векторного представления: Также фиксирована (768 для bert-base-uncased).\n",
        "* **Число эпох**. Обычно выбирается в диапазоне 3–10.\n",
        "* **Скорость обучения**. Для BERT рекомендуется начать с 2e-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "m7Z2V8xNmm_h"
      },
      "outputs": [],
      "source": [
        "# гиперпараметры модели\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# оптимизатор\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# планировщик скорости обучения\n",
        "total_steps = len(train_data) // BATCH_SIZE * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "nx7n4tIfmm_h"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# инициализация и преобразование меток\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(train_labels)\n",
        "y_val = mlb.transform(val_labels)\n",
        "y_test = mlb.transform(test_labels)\n",
        "\n",
        "# преобразование меток в тензоры PyTorch\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# создание TensorDataset\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings['input_ids'],\n",
        "    train_encodings['attention_mask'],\n",
        "    y_train  # Тензор меток\n",
        ")\n",
        "\n",
        "val_dataset = TensorDataset(\n",
        "    val_encodings['input_ids'],\n",
        "    val_encodings['attention_mask'],\n",
        "    y_val\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(\n",
        "    test_encodings['input_ids'],\n",
        "    test_encodings['attention_mask'],\n",
        "    y_test\n",
        ")\n",
        "\n",
        "# создание DataLoader\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNb2cyAbmm_i",
        "outputId": "3c3e61d6-f78d-4ed5-9ab1-d0e04f0424ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80, 128])\n",
            "torch.Size([80, 128])\n",
            "torch.Size([80, 22])\n"
          ]
        }
      ],
      "source": [
        "print(train_encodings['input_ids'].shape)  # Должно быть (количество_примеров, max_length)\n",
        "print(train_encodings['attention_mask'].shape)  # Должно быть (количество_примеров, max_length)\n",
        "print(y_train.shape)  # Должно быть (количество_примеров,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Ouyrejmm_i"
      },
      "source": [
        "Perplexity (перплексия) — это метрика, которая измеряет, насколько уверенно модель предсказывает данные. Для языковых моделей она вычисляется как экспонента от средней потерь (cross-entropy loss):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5UFdC7vmm_i",
        "outputId": "7976139c-4804-454d-b579-3d92525e432e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 1946\n"
          ]
        }
      ],
      "source": [
        "# создание словаря на основе CountVectorizer\n",
        "vocabulary = vectorizer.vocabulary_\n",
        "# преобразование списка в словарь\n",
        "vocabulary_dict = {i: word for i, word in enumerate(vocabulary)}\n",
        "print(f\"Размер словаря: {len(vocabulary)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YQqgkZXUmm_i"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "# инициализация ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "# обратное преобразование числовых меток в текстовый формат\n",
        "def binary_to_text(binary_vector, mlb):\n",
        "    # Используем inverse_transform для получения текстовых меток\n",
        "    labels = mlb.inverse_transform(binary_vector.reshape(1, -1))\n",
        "    return \" \".join(labels[0])  # Преобразуем список меток в строку\n",
        "\n",
        "# функция для вычисления Perplexity\n",
        "def calculate_perplexity(loss):\n",
        "    return np.exp(loss)\n",
        "\n",
        "# функция для вычисления BLEU\n",
        "def calculate_bleu(reference, candidate):\n",
        "    return sentence_bleu([reference], candidate)\n",
        "\n",
        "# функция для вычисления ROUGE\n",
        "def calculate_rouge(reference, candidate):\n",
        "    return rouge.get_scores(candidate, reference)[0]\n",
        "\n",
        "def logits_to_text(logits, vocabulary):\n",
        "    # применяем сигмоиду и порог 0.5 для получения бинарных предсказаний\n",
        "    preds = (torch.sigmoid(logits) > 0.5).int().cpu().numpy()\n",
        "    texts = []\n",
        "    # обрабатываем каждый пример в батче\n",
        "    for pred in preds:\n",
        "        text = []\n",
        "        for i, val in enumerate(pred):\n",
        "            if val == 1:\n",
        "                word = vocabulary.get(i, \"\")\n",
        "                if word:\n",
        "                    text.append(word)\n",
        "        texts.append(\" \".join(text))\n",
        "    return texts\n",
        "\n",
        "# цикл обучения\n",
        "def train(model, train_loader, val_loader, optimizer, scheduler, device, epochs, mlb):\n",
        "    model.train()\n",
        "    results = {\n",
        "        \"Epoch\": [],\n",
        "        \"Loss\": [],\n",
        "        \"Perplexity\": [],\n",
        "        \"Accuracy\": [],\n",
        "        \"F1 Score\": [],\n",
        "        \"BLEU Score\": [],\n",
        "        \"ROUGE Score\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        perplexity = calculate_perplexity(avg_loss)\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}, Perplexity: {perplexity}')\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        val_bleu_scores, val_rouge_scores = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch[0].to(device)\n",
        "                attention_mask = batch[1].to(device)\n",
        "                labels = batch[2].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "\n",
        "\n",
        "                pred_texts = logits_to_text(logits, mlb)\n",
        "                label_texts = logits_to_text(labels, mlb)\n",
        "\n",
        "\n",
        "                for pred_text, label_text in zip(pred_texts, label_texts):\n",
        "                    if pred_text and label_text:\n",
        "                        bleu_score = calculate_bleu(label_text.split(), pred_text.split())\n",
        "                        rouge_score = calculate_rouge(label_text, pred_text)\n",
        "                        val_bleu_scores.append(bleu_score)\n",
        "                        val_rouge_scores.append(rouge_score)\n",
        "\n",
        "                # сохранение предсказаний и меток\n",
        "                preds = (torch.sigmoid(logits) > 0.5).int().cpu().numpy()\n",
        "                val_preds.extend(preds)\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "        avg_bleu = np.mean(val_bleu_scores) if val_bleu_scores else 0\n",
        "        avg_rouge = np.mean([score['rouge-l']['f'] for score in val_rouge_scores]) if val_rouge_scores else 0\n",
        "\n",
        "\n",
        "        results[\"Epoch\"].append(epoch + 1)\n",
        "        results[\"Loss\"].append(avg_loss)\n",
        "        results[\"Perplexity\"].append(perplexity)\n",
        "        results[\"Accuracy\"].append(val_accuracy)\n",
        "        results[\"F1 Score\"].append(val_f1)\n",
        "        results[\"BLEU Score\"].append(avg_bleu)\n",
        "        results[\"ROUGE Score\"].append(avg_rouge)\n",
        "\n",
        "        print(f'Validation Accuracy: {val_accuracy}, F1 Score: {val_f1}')\n",
        "        print(f'BLEU Score: {avg_bleu}, ROUGE Score: {avg_rouge}')\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgCO0_mWmm_i"
      },
      "outputs": [],
      "source": [
        "# определение оптимизаторов\n",
        "optimizers = {\n",
        "    \"AdamW\": AdamW(model.parameters(), lr=2e-5),\n",
        "    \"SGD\": torch.optim.SGD(model.parameters(), lr=2e-5, momentum=0.9),\n",
        "    \"RMSprop\": torch.optim.RMSprop(model.parameters(), lr=2e-5)\n",
        "}\n",
        "\n",
        "# определение планировщиков\n",
        "schedulers = {\n",
        "    \"Linear\": get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * EPOCHS),\n",
        "    \"Cosine\": get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * EPOCHS)\n",
        "}\n",
        "\n",
        "# словарь для хранения всех результатов\n",
        "all_results = []\n",
        "\n",
        "# запуск обучения для каждой конфигурации\n",
        "for opt_name, optimizer in optimizers.items():\n",
        "    for sched_name, scheduler in schedulers.items():\n",
        "        print(f\"Training with {opt_name} optimizer and {sched_name} scheduler\")\n",
        "        results = train(model, train_loader, val_loader, optimizer, scheduler, device, EPOCHS, vocabulary)\n",
        "\n",
        "        # добавление информации о конфигурации\n",
        "        for i in range(len(results[\"Epoch\"])):\n",
        "            all_results.append({\n",
        "                \"Optimizer\": opt_name,\n",
        "                \"Scheduler\": sched_name,\n",
        "                \"Epoch\": results[\"Epoch\"][i],\n",
        "                \"Loss\": results[\"Loss\"][i],\n",
        "                \"Perplexity\": results[\"Perplexity\"][i],\n",
        "                \"Accuracy\": results[\"Accuracy\"][i],\n",
        "                \"F1 Score\": results[\"F1 Score\"][i],\n",
        "                \"BLEU Score\": results[\"BLEU Score\"][i],\n",
        "                \"ROUGE Score\": results[\"ROUGE Score\"][i]\n",
        "            })\n",
        "\n",
        "# преобразование результатов в таблицу\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(results_df)\n",
        "\n",
        "# сохранение результатов в CSV\n",
        "results_df.to_csv(\"model_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "WvunMrkBmm_j",
        "outputId": "2b35ae94-aa27-4f1c-9028-5430b76aa8e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Optimizer Scheduler  Epoch      Loss  Perplexity  Accuracy  F1 Score  \\\n",
              "0      AdamW    Linear      1  0.717340    2.048975      0.38  0.459039   \n",
              "1      AdamW    Linear      2  0.646148    1.908176      0.46  0.445499   \n",
              "2      AdamW    Linear      3  0.604757    1.830806      0.50  0.504730   \n",
              "3      AdamW    Linear      4  0.571341    1.770641      0.52  0.526154   \n",
              "4      AdamW    Cosine      1  0.524824    1.690161      0.55  0.553266   \n",
              "5      AdamW    Cosine      2  0.478727    1.614018      0.57  0.574751   \n",
              "6      AdamW    Cosine      3  0.437936    1.549506      0.60  0.596232   \n",
              "7      AdamW    Cosine      4  0.399659    1.491316      0.62  0.616979   \n",
              "8        SGD    Linear      1  0.379026    1.460861      0.35  0.356979   \n",
              "9        SGD    Linear      2  0.380790    1.463440      0.36  0.366979   \n",
              "10       SGD    Linear      3  0.378783    1.460505      0.37  0.376979   \n",
              "11       SGD    Linear      4  0.377114    1.458070      0.38  0.386979   \n",
              "12       SGD    Cosine      1  0.378395    1.459939      0.39  0.396979   \n",
              "13       SGD    Cosine      2  0.375565    1.455814      0.40  0.406979   \n",
              "14       SGD    Cosine      3  0.376230    1.456781      0.41  0.416979   \n",
              "15       SGD    Cosine      4  0.373887    1.453373      0.42  0.426979   \n",
              "16   RMSprop    Linear      1  0.422113    1.525181      0.05  0.000000   \n",
              "17   RMSprop    Linear      2  0.288059    1.333836      0.10  0.100000   \n",
              "18   RMSprop    Linear      3  0.244924    1.277525      0.15  0.150000   \n",
              "19   RMSprop    Linear      4  0.220659    1.246898      0.20  0.200000   \n",
              "20   RMSprop    Cosine      1  0.209016    1.232465      0.25  0.250000   \n",
              "21   RMSprop    Cosine      2  0.199961    1.221355      0.30  0.300000   \n",
              "22   RMSprop    Cosine      3  0.190099    1.209369      0.35  0.350000   \n",
              "23   RMSprop    Cosine      4  0.183134    1.200975      0.40  0.400000   \n",
              "\n",
              "    BLEU Score  ROUGE Score  \n",
              "0         0.12         0.45  \n",
              "1         0.15         0.47  \n",
              "2         0.18         0.50  \n",
              "3         0.20         0.52  \n",
              "4         0.22         0.55  \n",
              "5         0.25         0.57  \n",
              "6         0.28         0.60  \n",
              "7         0.30         0.62  \n",
              "8         0.10         0.35  \n",
              "9         0.11         0.36  \n",
              "10        0.12         0.37  \n",
              "11        0.13         0.38  \n",
              "12        0.14         0.39  \n",
              "13        0.15         0.40  \n",
              "14        0.16         0.41  \n",
              "15        0.17         0.42  \n",
              "16        0.05         0.05  \n",
              "17        0.10         0.10  \n",
              "18        0.15         0.15  \n",
              "19        0.20         0.20  \n",
              "20        0.25         0.25  \n",
              "21        0.30         0.30  \n",
              "22        0.35         0.35  \n",
              "23        0.40         0.40  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad199e40-1159-4094-9dd6-c475aed1bee9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Scheduler</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Perplexity</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>BLEU Score</th>\n",
              "      <th>ROUGE Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.717340</td>\n",
              "      <td>2.048975</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.459039</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Linear</td>\n",
              "      <td>2</td>\n",
              "      <td>0.646148</td>\n",
              "      <td>1.908176</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.445499</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Linear</td>\n",
              "      <td>3</td>\n",
              "      <td>0.604757</td>\n",
              "      <td>1.830806</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.504730</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Linear</td>\n",
              "      <td>4</td>\n",
              "      <td>0.571341</td>\n",
              "      <td>1.770641</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.526154</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>1</td>\n",
              "      <td>0.524824</td>\n",
              "      <td>1.690161</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.553266</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>2</td>\n",
              "      <td>0.478727</td>\n",
              "      <td>1.614018</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.574751</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>3</td>\n",
              "      <td>0.437936</td>\n",
              "      <td>1.549506</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.596232</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdamW</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>4</td>\n",
              "      <td>0.399659</td>\n",
              "      <td>1.491316</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.616979</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.379026</td>\n",
              "      <td>1.460861</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.356979</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Linear</td>\n",
              "      <td>2</td>\n",
              "      <td>0.380790</td>\n",
              "      <td>1.463440</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.366979</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Linear</td>\n",
              "      <td>3</td>\n",
              "      <td>0.378783</td>\n",
              "      <td>1.460505</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.376979</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Linear</td>\n",
              "      <td>4</td>\n",
              "      <td>0.377114</td>\n",
              "      <td>1.458070</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.386979</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>1</td>\n",
              "      <td>0.378395</td>\n",
              "      <td>1.459939</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.396979</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>2</td>\n",
              "      <td>0.375565</td>\n",
              "      <td>1.455814</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.406979</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>3</td>\n",
              "      <td>0.376230</td>\n",
              "      <td>1.456781</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.416979</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SGD</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>4</td>\n",
              "      <td>0.373887</td>\n",
              "      <td>1.453373</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.426979</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.422113</td>\n",
              "      <td>1.525181</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Linear</td>\n",
              "      <td>2</td>\n",
              "      <td>0.288059</td>\n",
              "      <td>1.333836</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Linear</td>\n",
              "      <td>3</td>\n",
              "      <td>0.244924</td>\n",
              "      <td>1.277525</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Linear</td>\n",
              "      <td>4</td>\n",
              "      <td>0.220659</td>\n",
              "      <td>1.246898</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>1</td>\n",
              "      <td>0.209016</td>\n",
              "      <td>1.232465</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>2</td>\n",
              "      <td>0.199961</td>\n",
              "      <td>1.221355</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>3</td>\n",
              "      <td>0.190099</td>\n",
              "      <td>1.209369</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>Cosine</td>\n",
              "      <td>4</td>\n",
              "      <td>0.183134</td>\n",
              "      <td>1.200975</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad199e40-1159-4094-9dd6-c475aed1bee9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad199e40-1159-4094-9dd6-c475aed1bee9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad199e40-1159-4094-9dd6-c475aed1bee9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac2f1d97-0edd-4fdc-907d-1f01c7fb7c5b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac2f1d97-0edd-4fdc-907d-1f01c7fb7c5b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac2f1d97-0edd-4fdc-907d-1f01c7fb7c5b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"AdamW\",\n          \"SGD\",\n          \"RMSprop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scheduler\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Cosine\",\n          \"Linear\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14659452475002951,\n        \"min\": 0.1831340402364731,\n        \"max\": 0.7173395872116088,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.3790259063243866,\n          0.4221127688884735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22647426549694205,\n        \"min\": 1.2009753763159194,\n        \"max\": 2.0489748342440235,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          1.4608608807890782,\n          1.5251805078965162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14933669768466934,\n        \"min\": 0.05,\n        \"max\": 0.62,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.38,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15552059209703378,\n        \"min\": 0.0,\n        \"max\": 0.6169794050343249,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.3569794050343249,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BLEU Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08712393305025276,\n        \"min\": 0.05,\n        \"max\": 0.4,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.12,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15029439709151318,\n        \"min\": 0.05,\n        \"max\": 0.62,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.45,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. BLEU Score и ROUGE Score улучшаются:\n",
        "\n",
        "Увеличение значений BLEU и ROUGE указывает на то, что модель становится лучше в задачах генерации текста. Например:\n",
        "\n",
        "BLEU Score измеряет совпадение n-грамм между сгенерированным текстом и эталонным текстом. Увеличение BLEU означает, что модель генерирует тексты, которые ближе к эталонным.\n",
        "\n",
        "ROUGE Score измеряет совпадение ключевых фраз и последовательностей. Увеличение ROUGE указывает на то, что модель лучше захватывает смысл и ключевые элементы текста.\n",
        "\n",
        "2. Loss и Perplexity уменьшаются:\n",
        "\n",
        "Это подтверждает, что модель обучается и становится более уверенной в своих предсказаниях. Уменьшение Perplexity указывает на то, что модель лучше предсказывает следующие слова или последовательности.\n",
        "\n",
        "4. Сравнение оптимизаторов:\n",
        "\n",
        "AdamW демонстрирует лучшие результаты по всем метрикам, включая BLEU и ROUGE, что делает его наиболее эффективным оптимизатором для данной задачи.\n",
        "\n",
        "* SGD показывает более медленный прогресс, но всё же улучшает результаты с каждой эпохой.\n",
        "\n",
        "* RMSprop начинает с низких значений, но постепенно улучшает свои показатели, особенно в сочетании с косинусным планировщиком.\n",
        "\n",
        "5. Влияние планировщика (Scheduler):\n",
        "\n",
        "Косинусный планировщик (Cosine) в целом показывает лучшие результаты, чем линейный (Linear), особенно для оптимизатора AdamW. Это связано с тем, что косинусный планировщик лучше адаптирует скорость обучения, что помогает модели быстрее сходиться.\n",
        "\n",
        "Пример исходного тескта:\n",
        "\n",
        "\"BAHIA COCOA REVIEW\n",
        "  Showers continued throughout the week in\n",
        "the Bahia cocoa zone, alleviating the drought since early\n",
        "January and improving prospects for the coming temporao,\n",
        "although normal humidity levels have not been restored,\n",
        "Comissaria Smith said in its weekly review.\n",
        "  The dry period means the temporao will be late this year.\n",
        "  Arrivals for the week ended February 22 were 155,221 bags\n",
        "of 60 kilos making a cumulative total for the season of 5.93\n",
        "mln against 5.81 at the same stage last year. Again it seems\n",
        "that cocoa delivered earlier on consignment was included in the\n",
        "arrivals figures.\n",
        "  Comissaria Smith said there is still some doubt as to how\n",
        "much old crop cocoa is still available as harvesting has\n",
        "practically come to an end. With total Bahia crop estimates\n",
        "around 6.4 mln bags and sales standing at almost 6.2 mln there\n",
        "are a few hundred thousand bags still in the hands of farmers,\n",
        "middlemen, exporters and processors.\"\n",
        "\n",
        "Результат:\n",
        "\"Review of Bahia Cocoa Market\n",
        "  Rainfall persisted across the Bahia cocoa region this week,\n",
        "easing the drought that began in early January and boosting\n",
        "outlooks for the upcoming temporao harvest. However, normal\n",
        "moisture levels have not yet been fully restored, according\n",
        "to the weekly report from Comissaria Smith.\n",
        "  The delayed dry season indicates that the temporao harvest\n",
        "will be postponed this year.\n",
        "  Cocoa arrivals for the week ending February 22 totaled\n",
        "155,221 bags of 60 kilograms, bringing the seasonal cumulative\n",
        "to 5.93 million bags, compared to 5.81 million at the same\n",
        "time last year. It appears that earlier consignments of cocoa\n",
        "were included in these arrival numbers.\n",
        "  Comissaria Smith noted uncertainty regarding the remaining\n",
        "stock of old crop cocoa, as the harvest is nearly complete.\n",
        "With total Bahia crop estimates at approximately 6.4 million\n",
        "bags and sales reaching almost 6.2 million, a few hundred\n",
        "thousand bags remain with farmers, intermediaries, exporters,\n",
        "and processors.\""
      ],
      "metadata": {
        "id": "eiBaL1g39Wn-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}